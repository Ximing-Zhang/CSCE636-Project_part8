# -*- coding: utf-8 -*-
"""CSCE636_train_part8.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1btZqztlykH_Y0V0cbmX6d-RToFsbAq3Q
"""

from google.colab import drive
drive.mount('/content/drive/')

# Commented out IPython magic to ensure Python compatibility.
# %tensorflow_version 1.x

#Prepareing Data
import cv2
import numpy as np
import os
import random
train_positive_path = '/content/drive/My Drive/data_new1/train/Positive'
train_negative_path = '/content/drive/My Drive/data_new1/train/Negative'
val_positive_path = '/content/drive/My Drive/data_new1/validation/Positive'
val_negative_path = '/content/drive/My Drive/data_new1/validation/Negative'

positive = os.listdir(train_positive_path)
negative = os.listdir(train_negative_path)
t = 31
l = 15
m = 6
x_train = []
y_train = []
x_val = []
y_val = []

def get_data(path, label):
  files = os.listdir(path) 
  X = []
  Y = []
  for file in files:
    print(file)
    videoCapture = cv2.VideoCapture(path + '/' + file) 
    frames = []
    while 1:
        success, frame = videoCapture.read()
        if not success:
            break
        #frame = cv2.resize(frame,(320,240),interpolation = cv2.INTER_AREA)
        frame = cv2.resize(frame,(299,299),interpolation = cv2.INTER_AREA)
        frames.append(frame)
    for j in range(0,len(frames)-t,l):
        data = frames[j:j+t:m]
        X.append(data)
        Y.append(label)
  return X, Y
X, Y = get_data(train_positive_path, 1)
x_train += X
y_train += Y
X, Y = get_data(train_negative_path, 0)
x_train += X
y_train += Y

X, Y = get_data(val_positive_path, 1)
x_val += X
y_val += Y
X, Y = get_data(val_negative_path, 0)
x_val += X
y_val += Y

print(len(x_train))
print(len(y_train))
print(len(x_val))
print(len(y_val))

x_train = np.asarray(x_train)
y_train = np.asarray(y_train)
x_val = np.asarray(x_val)
y_val = np.asarray(y_val)
print(np.shape(x_train))
print(np.shape(y_train))
print(np.shape(x_val))
print(np.shape(y_val))

from keras.models import Sequential , Model
from keras.layers import Dense , Activation, Conv2D, TimeDistributed, LSTM, Bidirectional, BatchNormalization
from keras.layers import Dropout , GlobalAveragePooling2D
from keras.layers import Flatten
from keras.constraints import maxnorm
from keras.optimizers import SGD , RMSprop , Adadelta , Adam
from keras.layers import Conv2D , BatchNormalization
from keras.layers import MaxPooling2D
from keras.utils import np_utils
from keras import backend as K
K.image_data_format() == 'channels_first'
from sklearn.model_selection import GridSearchCV
from keras.wrappers.scikit_learn import KerasClassifier
from keras.callbacks import ReduceLROnPlateau , ModelCheckpoint , LearningRateScheduler, EarlyStopping
from keras.applications.inception_v3 import InceptionV3
from keras.applications.resnet50 import ResNet50
# create the base pre-trained model
#Inceptionv3 = InceptionV3(weights='imagenet', include_top=True , input_shape=(240, 320, 3), pooling=None)
Resnet50 = ResNet50(weights='imagenet', include_top=False , input_shape=(299, 299, 3), pooling=None)
for layer in Resnet50.layers:
  layer.trainable = False
x = Resnet50.output
x = Conv2D(32, (3,3), activation='relu')(x)
x = Conv2D(64, (3,3), activation='relu')(x)
x = Conv2D(64, (3,3), activation='relu')(x)
ResNet50 = Model(Resnet50.input,x)
model = Sequential()
#model.add(TimeDistributed(Inceptionv3, input_shape=(6, 240, 320, 3)))
model.add(TimeDistributed(ResNet50, input_shape=(6, 299, 299, 3)))
# now, flatten on each output to send 5 
# outputs with one dimension to LSTM
model.add(TimeDistributed(Flatten()))
#dropout=0.1, recurrent_dropout=0.1,
model.add(LSTM(32, dropout=0.2, recurrent_dropout=0.1, return_sequences=True))
model.add(LSTM(32, dropout=0.2, recurrent_dropout=0.1, return_sequences=True))
model.add(LSTM(64, dropout=0.2, recurrent_dropout=0.1, return_sequences=False))
# finalize with standard Dense, Dropout...
model.add(Dense(128, activation='relu'))
model.add(Dropout(0.5))
model.add(Dense(1, activation='sigmoid'))

'''
x = base_model_Inceptionv3.output
x = Conv2D(32, (3,3), activation='relu', data_format='channels_first')(x)
x = MaxPooling2D((2, 2), dim_ordering="th")(x)
x = Conv2D(32, (3,3), activation='relu')(x)
x = MaxPooling2D((2, 2))(x)
x = Conv2D(32, (3,3), activation='relu')(x)
x = MaxPooling2D((2, 2))(x)
x = Conv2D(32, (3,3), activation='relu')(x)
x = MaxPooling2D((2, 2))(x)
'''
'''
model = models.Sequential()
#model.add(layers.Reshape((int(t/m),-1)))
model.add(layers.Conv2D(32, (3,3), activation='relu', input_shape=(6,8,2048)))
model.add(layers.MaxPooling2D((2, 2)))
model.add(layers.Conv2D(64, (3, 3), activation='relu'))
model.add(layers.MaxPooling2D((2, 2)))
model.add(layers.Conv2D(128, (3, 3), activation='relu'))
model.add(layers.MaxPooling2D((2, 2)))
model.add(layers.Conv2D(128, (3, 3), activation='relu'))
model.add(layers.MaxPooling2D((2, 2)))
model.add(layers.Flatten())
model.add(layers.LSTM(32,dropout=0.2,return_sequences=False,input_shape=(10,2048)))
#model.add(layers.LSTM(32))
#model.add(layers.LSTM(32,dropout=0.2,input_shape=(240, 320, 3)))
#model.add(layers.Flatten())
#model.add(layers.Dropout(0.5))
#model.add(layers.Dense(512, activation='relu'))
model.add(layers.Dense(1, activation='sigmoid'))

'''
from keras.optimizers import SGD
from keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau
sgd = SGD(lr=0.0005, decay = 1e-6, momentum=0.9, nesterov=True)
model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])
callbacks_list = [EarlyStopping(monitor='val_accuracy', patience=3), ModelCheckpoint("/content/drive/My Drive/model_part8_2.h5", monitor='val_accuracy', save_best_only=True) ]
#callbacks_list = [ModelCheckpoint("/content/drive/My Drive/model_part8_2.h5", monitor='val_accuracy', save_best_only=True) ]
history = model.fit(x_train,y_train, validation_data = (x_val , y_val), batch_size=64,epochs=50,callbacks=callbacks_list,shuffle=True)
#history = model.fit(train_images,train_labels, validation_data = (X_val, y_val), batch_size=8,epochs=50,callbacks=callbacks_list,shuffle=True)

print(model.summary())

validation_acc_history = history.history['val_accuracy']
validation_loss_history = history.history['val_loss']
import matplotlib.pyplot as plt
plt.plot(range(1, len(validation_acc_history) + 1), validation_acc_history)
plt.xlabel('Epochs')
plt.ylabel('Validation accuracy')
plt.show()
plt.plot(range(1, len(validation_loss_history) + 1), validation_loss_history)
plt.xlabel('Epochs')
plt.ylabel('Validation Loss')
plt.show()
print('Validation accuracy:',validation_acc_history)
print('validation loss:',validation_loss_history)

import os
import cv2
import random
import numpy as np
import tensorflow as tf
#path_test = '/content/drive/My Drive/data_new/train/Positive/v_BrushingTeeth_g22_c03.avi'
#path_test = '/content/drive/My Drive/CSCE636Project/5 Test Videos&Figure/video3.avi'
#path_test = '/content/drive/My Drive/video_test5.mp4'
path_test = '/content/drive/My Drive/data_new1/test/video_test2.mp4'
videoCapture = cv2.VideoCapture(path_test)
l = 30
frames = []
X = []
while 1 :
    success, frame = videoCapture.read()
    if not success:
        break
    #frame = cv2.resize(frame,(320,240),interpolation = cv2.INTER_AREA)
    frame = cv2.resize(frame,(299,299),interpolation = cv2.INTER_AREA)
    frames.append(frame)
for j in range(0,len(frames)-t,l):
    data = frames[j:j+t:m]
    X.append(data)
X = np.asarray(X)
res1 = model.predict(X)
res = []
for i in range(len(res1)):
  res.append(res1[i][0])
print(res)

pre = 0
start = []
end = []

for i in range(len(res)):
  if pre <= 0.5 and res[i] >0.5:
    start.append(i)
  elif pre >= 0.5 and res[i] < 0.5:
    end.append(i)
  pre = res[i]
print('start time:',start)
print('end time:',end)


import matplotlib.pyplot as plt
plt.plot(range(1, len(res) + 1), res)
plt.xlabel('Time')
plt.ylabel('Label')
plt.show()

print(len(res))

model_json = model.to_json()
with open("/content/drive/My Drive/model_part8_2.json", "w") as json_file:
    json_file.write(model_json)
# serialize weights to HDF5
model.save_weights("/content/drive/My Drive/model_part8_2.h5")
print("Saved model to disk")